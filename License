---

## 3. `rh_enforcer.py` (updated, copy–paste as a new file)

**Changes vs your draft:**

- **Fixed a math bug**: nats → log₁₀ conversion no longer divides by `log(2)`.
- Softened the final print so we’re honest: “under this model” not “proven”.

```python
#!/usr/bin/env python3
# =============================================================================
# RH ENFORCER v1.0 — Full Bayesian Penalty Against Counterexamples
# November 2025 — Weaponized for arXiv submission & public replication
# =============================================================================
#
# Computes:  log10(BF) = log10 P(data | RH true) / P(data | RH false with k spurious zeros)
#            → large positive values = strong evidence in favor of RH
#
# Requires:
#   - riemann_zeros_1e8.txt     → first 100,000,000 non-trivial zeros (Odlyzko-style)
#   - primes_up_to_1e8.txt      → all primes ≤ 10^8
#
# NOTE: For practical runs, start with truncated data (e.g. 10^4–10^5 zeros,
#       primes ≤ 10^6) or this will be computationally enormous.
# =============================================================================

import numpy as np
from scipy.stats import entropy
from scipy.integrate import simpson
import warnings

warnings.filterwarnings("ignore")

# -------------------------- 1. Load Real Data ---------------------------------

print("Loading zeros and primes...", end="", flush=True)
zeros = np.loadtxt("riemann_zeros_1e8.txt")      # imaginary parts γ_n only
primes = np.loadtxt("primes_up_to_1e8.txt", dtype=np.int64)
print(" Done")

X_MAX = float(primes[-1])
N_ZEROS = len(zeros)

# -------------------------- 2. GUE Spacing KL (fixed) -------------------------

print("Computing KL(p_emp || p_GUE) on unfolded prime gaps...", end="", flush=True)
gaps = np.diff(primes)
mean_log = np.log(primes[:-1])
s = gaps / mean_log                                 # unfolded spacings

# Histogram on [0, 6] with fixed binning
hist, edges = np.histogram(s, bins=400, range=(0.0, 6.0), density=True)
s_centers = 0.5 * (edges[:-1] + edges[1:])

def wigner_surmise(s_vals):
    """GUE / β=2 Wigner surmise PDF on spacings."""
    return (32.0 / np.pi**2) * s_vals**2 * np.exp(-4.0 * s_vals**2 / np.pi)

p_gue = wigner_surmise(s_centers)
p_gue /= simpson(p_gue, s_centers)                  # renormalize to 1
p_emp = hist + 1e-18                                 # avoid zeros

KL_SPACING_NATS = entropy(p_emp, p_gue)             # KL in nats
KL_SPACING_BITS = KL_SPACING_NATS / np.log(2.0)

print(f" Done → KL = {KL_SPACING_BITS:.6f} bits")

# -------------------------- 3. ψ(x) Explicit Formula Core ---------------------

def psi_explicit(xs, zeros_arr, betas=None):
    """
    ψ(x) ≈ x - ∑_{ρ} x^ρ/ρ   (real part, doubled for conjugate pairs)

    xs      : array of x values (real-positive)
    zeros_arr: array of imaginary parts γ_n
    betas   : array of real parts β_n (same length as zeros_arr)
              if None → all β = 1/2 (RH)
    """
    xs = np.asarray(xs, dtype=np.complex128)
    if betas is None:
        betas = np.full_like(zeros_arr, 0.5, dtype=np.float64)

    total = xs.copy()
    for beta, gamma in zip(betas, zeros_arr):
        rho = beta + 1j * gamma
        total -= xs**rho / rho
    return 2.0 * total.real                          # factor 2 for ±γ

# Sampling grid (log-spaced, good for oscillatory integrals)
NUM_X = 800
xs = np.logspace(3.0, np.log10(X_MAX), NUM_X)
log_xs = np.log(xs)

# Baseline under RH (all β = 1/2)
psi_rh = psi_explicit(xs, zeros)

# -------------------------- 4. Energy Functional E[β] -------------------------

def energy_functional(psi_vals, xs_grid, log_x_grid):
    """
    Energy-like functional measuring deviation of ψ(x) from x,
    rescaled by sqrt(x) and integrated over log x.

    E = ∫ ((ψ(x) - x)/sqrt(x))^2 * (1/x) d(log x)
    """
    xs_grid = np.asarray(xs_grid, dtype=np.float64)
    psi_vals = np.asarray(psi_vals, dtype=np.float64)

    error = (psi_vals - xs_grid) / np.sqrt(xs_grid)
    weight = 1.0 / xs_grid
    integrand = error**2 * weight

    return simpson(integrand, log_x_grid)

E_RH = energy_functional(psi_rh, xs, log_xs)

# Calibrate λ so that on RH-true data: λ × E_RH ≈ KL_spacing (in nats)
lam = KL_SPACING_NATS / max(E_RH, 1e-30)

print(f"E_RH = {E_RH:.3e}, λ = {lam:.3e}")

# -------------------------- 5. Misfit for Hypothetical Violations -------------

def misfit_increase(betas_fake, gammas_fake=None):
    """
    Add k spurious zeros (possibly off the line) and return ΔM = M_fake - M_RH.

    betas_fake : list/array of β values for counterfeit zeros
    gammas_fake: optional list/array of γ values; if None, reuse lowest heights
                 zeros[:k] as a pessimistic (worst-case) placement.
    """
    betas_fake = np.asarray(betas_fake, dtype=np.float64)
    k = len(betas_fake)

    if gammas_fake is None:
        gammas_fake = zeros[:k]
    gammas_fake = np.asarray(gammas_fake, dtype=np.float64)

    # Full set of real parts: (N_ZEROS on the line) + k off-line
    betas_full = np.concatenate([np.full(N_ZEROS, 0.5, dtype=np.float64),
                                 betas_fake])
    # Full set of imaginary parts: original zeros + fake ones
    gammas_full = np.concatenate([zeros, gammas_fake])

    psi_fake = psi_explicit(xs, gammas_full, betas_full)
    E_fake = energy_functional(psi_fake, xs, log_xs)
    delta_E = E_fake - E_RH
    return lam * delta_E                            # in nats

# -------------------------- 6. Full Bayesian Evidence Engine ------------------

def log10_bayes_factor_against(k_spurious=1, beta=0.75, height_strategy="lowest"):
    """
    log10 Bayes factor in favor of RH against exactly k spurious zeros
    at real part β, placed at the lowest available heights (worst case
    under this toy model).

    Parameters
    ----------
    k_spurious : int
        Number of counterfeit zeros.
    beta : float
        Real part of each counterfeit zero.
    height_strategy : str
        Currently only 'lowest' is implemented; kept for future extensions.
    """
    betas_fake = [beta] * k_spurious

    if height_strategy != "lowest":
        raise NotImplementedError("Only 'lowest' height_strategy is implemented.")

    delta_M_nats = misfit_increase(betas_fake)
    # Convert nats → log10: divide by ln(10)
    log10_BF = delta_M_nats / np.log(10.0)
    return log10_BF

# -------------------------- 7. Precomputed Table (Instant Results) ------------

print("\n" + "=" * 80)
print("           RIEMANN HYPOTHESIS BAYESIAN ENFORCER — NOVEMBER 2025")
print("=" * 80)
print(f"Data: {N_ZEROS:,} zeros, primes ≤ {X_MAX:,.0f}")
print(f"KL(spacing) = {KL_SPACING_BITS:.6f} bits")
print(f"λ × E_RH term = {lam * E_RH:.6f} nats (calibrated to match KL)\n")

print("log10(Bayes factor in favor of RH) against k counterfeit zeros at Re(ρ)=β:")
print("     β \\ k-spurious →   1         2         5        10        50       100")
print("-" * 80)

k_values = [1, 2, 5, 10, 50, 100]
beta_values = [0.51, 0.55, 0.60, 0.70, 0.80, 0.90, 0.99]

for beta in beta_values:
    row = f"{beta:4.2f} | "
    for k in k_values:
        bf = log10_bayes_factor_against(k_spurious=k, beta=beta)
        if bf > 9999:
            row += " >1e4    "
        else:
            row += f"{bf:8.1f}  "
    print(row)

print("-" * 80)
print("\nInterpretation (model-dependent):")
print("• Under this Bayesian model, a single zero at β ≈ 0.70 typically yields")
print("  an enormous log10 Bayes factor in favor of RH (data vs that scenario).")
print("• To compensate with spacing violations alone, one would need an unreal")
print("  number of coordinated counterfeit zeros under this toy likelihood.")
print("• This is *evidence modeling*, not a formal proof of RH.")

# -------------------------- 8. One-liner for any scenario --------------------

print("\nQuick check helper (within this script):")
print("""
def rh_evidence(beta, k=1):
    \\"\\"
    Return log10 Bayes factor in favor of RH against k zeros at Re(ρ)=beta
    under the current model and data.
    \\"\\"
    return log10_bayes_factor_against(k_spurious=k, beta=beta)

# Examples (order-of-magnitude only, depends on data/truncation):
#   rh_evidence(0.75, 1)
#   rh_evidence(0.99, 100)
""")

print("\nUnder the current model and data, RH receives overwhelming Bayesian")
print("support against these specific off-line zero scenarios.")
print("This does *not* constitute a formal mathematical proof of RH.")
print("=" * 77 + "\n")
